{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e41804-30bf-422a-90be-ab1195987fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:31:36.764070Z",
     "iopub.status.busy": "2024-04-08T22:31:36.763641Z",
     "iopub.status.idle": "2024-04-08T22:31:38.969299Z",
     "shell.execute_reply": "2024-04-08T22:31:38.968658Z",
     "shell.execute_reply.started": "2024-04-08T22:31:36.764043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d263d825-d109-48c1-a1cb-9a42600e6065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:31:38.970819Z",
     "iopub.status.busy": "2024-04-08T22:31:38.970335Z",
     "iopub.status.idle": "2024-04-08T22:31:39.253422Z",
     "shell.execute_reply": "2024-04-08T22:31:39.252652Z",
     "shell.execute_reply.started": "2024-04-08T22:31:38.970787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a994ffb6-d6f5-4035-b192-3b2966ed10e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:32:11.774487Z",
     "iopub.status.busy": "2024-04-08T22:32:11.773640Z",
     "iopub.status.idle": "2024-04-08T22:32:27.938088Z",
     "shell.execute_reply": "2024-04-08T22:32:27.937343Z",
     "shell.execute_reply.started": "2024-04-08T22:32:11.774443Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010773 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment\n",
       "0            0                                         NC and NH.\n",
       "1            0  You do know west teams play against west teams...\n",
       "2            0  They were underdogs earlier today, but since G...\n",
       "3            0  This meme isn't funny none of the \"new york ni...\n",
       "4            0                    I could use one of those tools.\n",
       "...        ...                                                ...\n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...\n",
       "1010822      1                 whatever you do, don't vote green!\n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...\n",
       "1010824      1  The Slavs got their own country - it is called...\n",
       "1010825      1  values, as in capitalism .. there is good mone...\n",
       "\n",
       "[1010773 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sarcasm-detector/data/train-balanced-sarcasm.csv')\n",
    "df = df.drop(['author','date','created_utc','parent_comment','subreddit','downs','ups','score'],axis=1)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02c9a2-ff5b-449f-a0bd-48785bb05809",
   "metadata": {},
   "source": [
    "Гипотезы:\n",
    "1) Не удалять скобки, двоеточия, знаки вопроса (для этого сплитать по твитам)\n",
    "2) Проверть caps - если все слово написано капсом, то его не переводим в нижний регистр (проверка с помощью метода isupper())\n",
    "3) Исправить сплит строк, сгенерировав новый вид символа - много знаков вопросов, много восклицательных знаков (многоточие уже есть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4139bfaf-8d9b-400c-8164-e7220db1cf9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:33:42.593188Z",
     "iopub.status.busy": "2024-04-08T22:33:42.592536Z",
     "iopub.status.idle": "2024-04-08T22:36:36.849955Z",
     "shell.execute_reply": "2024-04-08T22:36:36.849340Z",
     "shell.execute_reply.started": "2024-04-08T22:33:42.593157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not drafting Reed, Olsen, or Gronk at where th...</td>\n",
       "      <td>[drafting, reed, olsen, gronk, they'll, likely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't you just love the FPTP.</td>\n",
       "      <td>[love, FPTP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The question is why Chief Delphi, TBA, and the...</td>\n",
       "      <td>[question, chief, delphi, TBA, subreddit, gone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easier gold farm is warrior Bolster, Target Du...</td>\n",
       "      <td>[easier, gold, farm, warrior, bolster, target,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a cuck!</td>\n",
       "      <td>[cuck, featuremark]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758074</th>\n",
       "      <td>Pirate it!</td>\n",
       "      <td>[pirate, featuremark]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758075</th>\n",
       "      <td>My state does the on call judges too.</td>\n",
       "      <td>[state, call, judges]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758076</th>\n",
       "      <td>Temporal displacement</td>\n",
       "      <td>[temporal, displacement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758077</th>\n",
       "      <td>God it's like people who idolize Tony Montana ...</td>\n",
       "      <td>[god, like, people, idolize, tony, montana, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758078</th>\n",
       "      <td>:(</td>\n",
       "      <td>[:(]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758079 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment                                               prep\n",
       "0       Not drafting Reed, Olsen, or Gronk at where th...  [drafting, reed, olsen, gronk, they'll, likely...\n",
       "1                           Don't you just love the FPTP.                                       [love, FPTP]\n",
       "2       The question is why Chief Delphi, TBA, and the...  [question, chief, delphi, TBA, subreddit, gone...\n",
       "3       easier gold farm is warrior Bolster, Target Du...  [easier, gold, farm, warrior, bolster, target,...\n",
       "4                                            What a cuck!                                [cuck, featuremark]\n",
       "...                                                   ...                                                ...\n",
       "758074                                         Pirate it!                              [pirate, featuremark]\n",
       "758075              My state does the on call judges too.                              [state, call, judges]\n",
       "758076                              Temporal displacement                           [temporal, displacement]\n",
       "758077  God it's like people who idolize Tony Montana ...  [god, like, people, idolize, tony, montana, wa...\n",
       "758078                                                 :(                                               [:(]\n",
       "\n",
       "[758079 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = re.sub('[?!]+',' featuremark ',text)\n",
    "    text = re.sub('\\.{2,}',' featuredot ',text)\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "\n",
    "    words = TweetTokenizer().tokenize(text)\n",
    "    punct = list(string.punctuation)\n",
    "\n",
    "    words = [word.lower() if not word.isupper() else word for word in words ]\n",
    "    custom_sw = [\"'s\",\"``\",\"'m\",\"'d\",\"'re\",\"--\", \"(\",\")\",\"'d\",\"\",\" \",\"n't\",\"'t\",\"'\"]\n",
    "    sw = set(list(stopwords.words('english')) + punct + custom_sw)\n",
    "    words = [word for word in words if word not in sw]\n",
    "\n",
    "    return  words\n",
    "\n",
    "def create_prep_dataframe(series):\n",
    "  df = series.to_frame()\n",
    "  df['prep'] = df.comment.apply(preprocessing)\n",
    "  df = df.reset_index(drop=True)\n",
    "  return df\n",
    "\n",
    "series_train, series_test, y_train, y_test = train_test_split(df['comment'],df.label,test_size= 0.25, random_state = 42)\n",
    "df_train = create_prep_dataframe(series_train)\n",
    "df_test = create_prep_dataframe(series_test)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79662fa6-939f-44c8-88f0-db165f871f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:36:36.851668Z",
     "iopub.status.busy": "2024-04-08T22:36:36.851034Z",
     "iopub.status.idle": "2024-04-08T22:37:07.774583Z",
     "shell.execute_reply": "2024-04-08T22:37:07.773889Z",
     "shell.execute_reply.started": "2024-04-08T22:36:36.851631Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "\n",
    "df_train['prep_str'] = df_train.prep.apply(lambda x: ' '.join(x))\n",
    "df_test['prep_str'] = df_test.prep.apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_train = tfidf.fit_transform(df_train.prep_str)\n",
    "X_test = tfidf.transform(df_test.prep_str)\n",
    "\n",
    "y_train_cleaned, y_test_cleaned = y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d892c6a9-7e5d-412e-bc10-17d0c06caf0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:37:07.776126Z",
     "iopub.status.busy": "2024-04-08T22:37:07.775750Z",
     "iopub.status.idle": "2024-04-08T22:37:07.787953Z",
     "shell.execute_reply": "2024-04-08T22:37:07.787382Z",
     "shell.execute_reply.started": "2024-04-08T22:37:07.776092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758079, 5059349)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e55772-a6f1-4eed-847f-d90dadc3e7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:37:07.789773Z",
     "iopub.status.busy": "2024-04-08T22:37:07.789243Z",
     "iopub.status.idle": "2024-04-08T22:37:38.317539Z",
     "shell.execute_reply": "2024-04-08T22:37:38.316744Z",
     "shell.execute_reply.started": "2024-04-08T22:37:07.789737Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.6939471664654866\n",
      "f1 micro: 0.6939658242775848\n",
      "f1 weighted: 0.6939787892346989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "params = {'tol':[1e-2,1e-2,1e-3,1e-4,1e-5,1e-6],\n",
    "         'C':np.arange(1,5,0.5),\n",
    "         'random_state':[42],\n",
    "         'n_jobs':[-1],\n",
    "         'max_iter':[300],\n",
    "         'solver':['sag','saga']}\n",
    "\n",
    "\n",
    "# best params: {'tol': 1e-06, 'solver': 'sag', 'random_state': 42, 'n_jobs': -1, 'max_iter': 300, 'C': 2.0}\n",
    "model = LogisticRegression(tol=1e-6,solver='sag',random_state=42,n_jobs=-1,max_iter=300,C=2.0)\n",
    "model.fit(X_train,y_train_cleaned)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'f1 macro: {f1_score(y_pred,y_test_cleaned,average=\"macro\")}')\n",
    "print(f'f1 micro: {f1_score(y_pred,y_test_cleaned,average=\"micro\")}')\n",
    "print(f'f1 weighted: {f1_score(y_pred,y_test_cleaned,average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d71a18-1844-41eb-93c1-64151f042439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T22:50:27.948037Z",
     "iopub.status.busy": "2024-04-08T22:50:27.947384Z",
     "iopub.status.idle": "2024-04-08T22:50:28.188167Z",
     "shell.execute_reply": "2024-04-08T22:50:28.187500Z",
     "shell.execute_reply.started": "2024-04-08T22:50:27.947999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sarcasm-detector/models/LogReg.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model, 'sarcasm-detector/models/LogReg.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
